{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-10T12:28:25.966778Z","iopub.execute_input":"2022-11-10T12:28:25.967275Z","iopub.status.idle":"2022-11-10T12:28:25.978805Z","shell.execute_reply.started":"2022-11-10T12:28:25.967237Z","shell.execute_reply":"2022-11-10T12:28:25.976969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DATA LOADING & PlOTTING","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:28:25.983510Z","iopub.execute_input":"2022-11-10T12:28:25.984185Z","iopub.status.idle":"2022-11-10T12:28:26.013859Z","shell.execute_reply.started":"2022-11-10T12:28:25.984132Z","shell.execute_reply":"2022-11-10T12:28:26.011813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import file part and data and reduce memory cost by data \n# Import path files\nfile_path = '../input/ieee-fraud-detection'\n# import file \ntrain_identity = pd.read_csv('../input/ieee-fraud-detection/train_identity.csv')\n#reduce the file \ntrain_identity = reduce_mem_usage(train_identity)\ntrain_transaction = pd.read_csv(f'{file_path}/train_transaction.csv')\ntrain_transaction = reduce_mem_usage(train_transaction)\ntest_identity = pd.read_csv(f'{file_path}/test_identity.csv')\ntrain_identity = reduce_mem_usage(test_identity)\ntest_transaction = pd.read_csv(f'{file_path}/test_transaction.csv')\ntest_transaction = reduce_mem_usage(test_transaction)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:28:26.015757Z","iopub.execute_input":"2022-11-10T12:28:26.016873Z","iopub.status.idle":"2022-11-10T12:32:43.997228Z","shell.execute_reply.started":"2022-11-10T12:28:26.016812Z","shell.execute_reply":"2022-11-10T12:32:43.995390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\ntest.columns = train.drop('isFraud', axis=1).columns\n\ndel train_identity\ndel train_transaction\ndel test_identity\ndel test_transaction\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:32:44.000413Z","iopub.execute_input":"2022-11-10T12:32:44.001290Z","iopub.status.idle":"2022-11-10T12:32:50.738725Z","shell.execute_reply.started":"2022-11-10T12:32:44.001243Z","shell.execute_reply":"2022-11-10T12:32:50.737011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a submission file\nsubmission = pd.DataFrame({'TransactionID':test.TransactionID})\nprint(submission.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:32:50.740522Z","iopub.execute_input":"2022-11-10T12:32:50.741018Z","iopub.status.idle":"2022-11-10T12:32:50.753762Z","shell.execute_reply.started":"2022-11-10T12:32:50.740970Z","shell.execute_reply":"2022-11-10T12:32:50.752510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n#from matplotlib import pyplot as plt\n#plt.figure(figsize=(10,10))\n\n#sns.histplot(data= train,  x=\"TransactionDT\", hue = \"isFraud\")","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:32:50.755934Z","iopub.execute_input":"2022-11-10T12:32:50.756791Z","iopub.status.idle":"2022-11-10T12:32:50.764510Z","shell.execute_reply.started":"2022-11-10T12:32:50.756742Z","shell.execute_reply":"2022-11-10T12:32:50.763064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(10,10))\n\n#sns.histplot(data= train,  x=\"TransactionAmt\",bins = 30, hue = \"isFraud\", log_scale = True)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:32:50.766260Z","iopub.execute_input":"2022-11-10T12:32:50.767026Z","iopub.status.idle":"2022-11-10T12:32:50.777821Z","shell.execute_reply.started":"2022-11-10T12:32:50.766990Z","shell.execute_reply":"2022-11-10T12:32:50.776782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2022-10-28T09:33:06.295597Z","iopub.execute_input":"2022-10-28T09:33:06.295954Z","iopub.status.idle":"2022-10-28T09:33:06.528791Z","shell.execute_reply.started":"2022-10-28T09:33:06.295921Z","shell.execute_reply":"2022-10-28T09:33:06.527347Z"}}},{"cell_type":"markdown","source":"Choose data set and standardize data ","metadata":{}},{"cell_type":"code","source":"\n# Preprocessing X and create a validation subset \ntrain.sort_values('TransactionDT', inplace=True)\nX_test = test\ndel test\ngc.collect()\nX = train.drop(['isFraud'], axis=1)\nlength_X_train_val = len(X)\n# Cleaning data process \nX_train_test_combined = pd.concat([X.drop(columns= 'TransactionID'), X_test.drop(columns='TransactionID')])\n# Missing values check\n# Dropping columns with more than 20% missing values \nmv = X_train_test_combined.isnull().sum()/len(X_train_test_combined)\nX_train_test_combined = X_train_test_combined.drop(columns=mv[mv>0.2].index)\nprint(X_train_test_combined.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:32:50.779704Z","iopub.execute_input":"2022-11-10T12:32:50.780233Z","iopub.status.idle":"2022-11-10T12:33:03.135880Z","shell.execute_reply.started":"2022-11-10T12:32:50.780197Z","shell.execute_reply":"2022-11-10T12:33:03.134204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n#Fill the missing data in num columns\n# Find the column with numbers \nX_train_test_num = X_train_test_combined.select_dtypes(include=np.number)\nprint(X_train_test_num.shape)\nimp_median = SimpleImputer(missing_values=np.nan, strategy='median')\nX_num_df = pd.DataFrame(imp_median.fit_transform(X_train_test_num), columns=X_train_test_num.columns)\ndel X_train_test_num\nprint(X_num_df.shape)\n# Fill the missing data in catogorial columns with the most frequent\nX_train_test_cat = X_train_test_combined.select_dtypes(exclude=np.number)\nprint(X_train_test_cat.shape)\nimp_most_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nX_cat_df = pd.DataFrame(imp_most_freq.fit_transform(X_train_test_cat), columns=X_train_test_cat.columns)\ndel X_train_test_cat\nprint(X_cat_df.shape)\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:03.140157Z","iopub.execute_input":"2022-11-10T12:33:03.140599Z","iopub.status.idle":"2022-11-10T12:33:36.162663Z","shell.execute_reply.started":"2022-11-10T12:33:03.140565Z","shell.execute_reply":"2022-11-10T12:33:36.161057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine num and cat data\nX_data_after_cleaning = pd.concat([X_num_df, X_cat_df], axis=1)\ndel X_num_df, X_cat_df\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:36.164435Z","iopub.execute_input":"2022-11-10T12:33:36.164925Z","iopub.status.idle":"2022-11-10T12:33:36.800962Z","shell.execute_reply.started":"2022-11-10T12:33:36.164863Z","shell.execute_reply":"2022-11-10T12:33:36.799510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# One hot coding \nX_data_encoded = pd.get_dummies(X_data_after_cleaning, drop_first=True)\n\n\n\n# Seperate the train_valuate and test data \nX_train_val = X_data_encoded.iloc[:length_X_train_val]\nX_test_data = X_data_encoded.iloc[length_X_train_val:]\nprint(X_test_data.shape)\n\n\ny = train['isFraud']\n\nsplitting_index = int(0.70*len(X_train_val))\nprint(\"splitting index:\",splitting_index)\nX_train = X_train_val.iloc[:splitting_index].values\nX_val = X_train_val.iloc[splitting_index:].values\ny_train = y.iloc[:splitting_index].values\ny_val = y.iloc[splitting_index:].values\nX_test_data = X_test_data.values\nprint(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\ndel y, train\ndel X_data_encoded\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:36.802504Z","iopub.execute_input":"2022-11-10T12:33:36.803158Z","iopub.status.idle":"2022-11-10T12:33:39.415965Z","shell.execute_reply.started":"2022-11-10T12:33:36.803120Z","shell.execute_reply":"2022-11-10T12:33:39.414266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test_data)\n\npd.value_counts(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:39.417662Z","iopub.execute_input":"2022-11-10T12:33:39.418518Z","iopub.status.idle":"2022-11-10T12:33:41.972604Z","shell.execute_reply.started":"2022-11-10T12:33:39.418475Z","shell.execute_reply":"2022-11-10T12:33:41.971243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()\nX_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\nprint(X_train_smote.shape, y_train_smote.shape)\ndel X_train_scaled, y_train\npd.value_counts(y_train_smote)","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:41.974695Z","iopub.execute_input":"2022-11-10T12:33:41.975120Z","iopub.status.idle":"2022-11-10T12:33:50.655224Z","shell.execute_reply.started":"2022-11-10T12:33:41.975086Z","shell.execute_reply":"2022-11-10T12:33:50.653670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use parameter search for XGBoost\n\"\"\"from sklearn.model_selection import RandomizedSearchCV\n\nimport xgboost as xgb\nparams = { 'max_depth': [3, 5, 6, 10, 15, 20],\n           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n           'subsample': np.arange(0.5, 1.0, 0.1),\n           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n           'n_estimators': [100, 500, 1000]}\nxgbr = xgb.XGBClassifier(seed = 20)\nclf = RandomizedSearchCV(estimator=xgbr,\n                         param_distributions=params,\n                         scoring='neg_mean_squared_error',\n                         n_iter=25,\n                         verbose=1)\nclf.fit(X_train_smote, y_train_smote)\nprint(\"Best parameters:\", clf.best_params_)\nprint(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:50.657027Z","iopub.execute_input":"2022-11-10T12:33:50.657542Z","iopub.status.idle":"2022-11-10T12:33:50.667449Z","shell.execute_reply.started":"2022-11-10T12:33:50.657505Z","shell.execute_reply":"2022-11-10T12:33:50.665450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import xgboost as xgb\nclf = xgb.XGBClassifier( \n        n_estimators=2000,\n        max_depth=12, \n        learning_rate=0.02, \n        subsample=0.8,\n        colsample_bytree=0.4, \n        missing=-1, \n        eval_metric='auc',\n        # USE CPU\n        nthread=4,\n        tree_method='hist' \n        # USE GPU\n        #tree_method='gpu_hist' \n    )\nclf.fit(X_train_smote, y_train_smote)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:33:50.669301Z","iopub.execute_input":"2022-11-10T12:33:50.669695Z","iopub.status.idle":"2022-11-10T12:33:50.682666Z","shell.execute_reply.started":"2022-11-10T12:33:50.669658Z","shell.execute_reply":"2022-11-10T12:33:50.681670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Baysian optimization\nimport xgboost as xgb\nimport hyperopt\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\nspace={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n        'gamma': hp.uniform ('gamma', 1,9),\n        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n        'n_estimators': 180,\n        'seed': 0\n    }","metadata":{"execution":{"iopub.status.busy":"2022-11-10T12:36:28.289022Z","iopub.execute_input":"2022-11-10T12:36:28.289637Z","iopub.status.idle":"2022-11-10T12:36:28.426800Z","shell.execute_reply.started":"2022-11-10T12:36:28.289597Z","shell.execute_reply":"2022-11-10T12:36:28.425047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\"\"\"def objective(space):\n    clf=xgb.XGBClassifier(\n                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n                    colsample_bytree=int(space['colsample_bytree']))\n    \n    evaluation = [( X_train_smote, y_train_smote), ( X_val_scaled, y_val)]\n    \n    clf.fit(X_train_smote, y_train_smote,\n            eval_set=evaluation, eval_metric=\"auc\",\n            early_stopping_rounds=100,verbose=False)\n    \n\n    y_predproba = clf.predict(X_val_scaled)\n    accuracy = accuracy_score(y_val, y_predproba>0.5)\n    print (\"SCORE:\", accuracy)\n    return {'loss': -accuracy, 'status': STATUS_OK }\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-10T13:07:24.315521Z","iopub.execute_input":"2022-11-10T13:07:24.316038Z","iopub.status.idle":"2022-11-10T13:07:24.326459Z","shell.execute_reply.started":"2022-11-10T13:07:24.316002Z","shell.execute_reply":"2022-11-10T13:07:24.324749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"trials = Trials()\n\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 100,\n                        trials = trials)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-10T13:07:28.325321Z","iopub.execute_input":"2022-11-10T13:07:28.325790Z","iopub.status.idle":"2022-11-10T17:23:04.169950Z","shell.execute_reply.started":"2022-11-10T13:07:28.325757Z","shell.execute_reply":"2022-11-10T17:23:04.168061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-10T17:23:04.434934Z","iopub.execute_input":"2022-11-10T17:23:04.435374Z","iopub.status.idle":"2022-11-10T17:23:04.441481Z","shell.execute_reply.started":"2022-11-10T17:23:04.435339Z","shell.execute_reply":"2022-11-10T17:23:04.440338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"{'colsample_bytree': 0.5410395070950723, 'gamma': 2.7097670582231093, 'max_depth': #18.0, 'min_child_weight': 2.0, 'reg_alpha': 41.0, 'reg_lambda': 0.4283447596194464}\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf=xgb.XGBClassifier(\n                    n_estimators =180, max_depth =18 , gamma = 2.709767,\n                    reg_alpha =41 ,min_child_weight=2,\n                    colsample_bytree=0.541)\n    \nevaluation = [( X_train_smote, y_train_smote), ( X_val_scaled, y_val)]\n    \nclf.fit(X_train_smote, y_train_smote,\n            eval_set=evaluation, eval_metric=\"auc\",\n            early_stopping_rounds=100,verbose=False)\n    \n\ny_predproba = clf.predict(X_val_scaled)\naccuracy = accuracy_score(y_val, y_predproba>0.5)\nprint (\"SCORE:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T18:05:31.187692Z","iopub.execute_input":"2022-11-10T18:05:31.189473Z","iopub.status.idle":"2022-11-10T18:34:39.018628Z","shell.execute_reply.started":"2022-11-10T18:05:31.189394Z","shell.execute_reply":"2022-11-10T18:34:39.017216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ny_predproba = clf.predict_proba(X_val_scaled)[:,1]\nprint(f'Validation AUC={roc_auc_score(y_val, y_predproba)}')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T18:46:09.852851Z","iopub.execute_input":"2022-11-10T18:46:09.853932Z","iopub.status.idle":"2022-11-10T18:46:11.073052Z","shell.execute_reply.started":"2022-11-10T18:46:09.853846Z","shell.execute_reply":"2022-11-10T18:46:11.071695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction Submission ","metadata":{}},{"cell_type":"code","source":"# Predict in valuation set \ny_pred_test = clf.predict_proba(X_test_scaled)[:,1]\nsubmission['isFraud'] = y_pred_test\nprint(submission.shape)\nsubmission.head()\nsubmission.to_csv('submission.csv', index=False)\nprint('Submission is successful!')\n","metadata":{"execution":{"iopub.status.busy":"2022-11-10T18:46:19.541281Z","iopub.execute_input":"2022-11-10T18:46:19.541726Z","iopub.status.idle":"2022-11-10T18:46:25.516210Z","shell.execute_reply.started":"2022-11-10T18:46:19.541689Z","shell.execute_reply":"2022-11-10T18:46:25.514782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}